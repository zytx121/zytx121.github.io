---
permalink: /
title: "Wenwei Zhang, 张文蔚"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Wenwei Zhang is a final year Ph.D. student at the [School of Computer Science and Engineering](http://scse.ntu.edu.sg/Pages/Home.aspx), Nanyang Technological University, Singapore. He is a member of [NTU MMLab](https://www.mmlab-ntu.com/), affiliated with the NTU S-Lab, supervised by Professor [Chen Change (Cavan) Loy](http://personal.ie.cuhk.edu.hk/~ccloy/).
He also works closely with [Jiangmiao Pang](https://oceanpang.github.io/) and [Kai Chen](http://chenkai.site/), focusing on object recognition and scene understanding tasks.
Before that, he received his bachelor degree at the [Computer Science School](http://cs.whu.edu.cn/), Wuhan University.
You can find his CV [here](/files/resume.pdf).

His main works lie in *Unified Framework for X*, which include [unified image](https://www.mmlab-ntu.com/project/knet/index.html), [video](https://github.com/lxtGH/Video-K-Net), and point segmentation, [Dense Unsupervised Learning](https://www.mmlab-ntu.com/project/densesiam/index.html), and [robust multi-modality multi-object tracking](https://github.com/ZwwWayne/mmMOT).

He led the initial release of [MMEngine](https://github.com/open-mmlab/mmengine), the core of [OpenMMLab 2.0](https://openmmlab.com/).
He built and released [MMDetection3D](https://github.com/open-mmlab/mmdetection3d), and has been leading the development of [MMDetection](https://github.com/open-mmlab/mmdetection) and [MMDetection3D](https://github.com/open-mmlab/mmdetection3d) since 2020, respectively. He has been a core maintainer of [OpenMMLab projects](https://openmmlab.com/) since 2019.

Recent News
------------------------

3 papers ([BARON](https://arxiv.org/abs/2302.13996), [MV-JAR](https://arxiv.org/abs/2303.13510), and [DDQ](https://arxiv.org/abs/2303.12776)) are accepted by CVPR2023. (Mar. 2023)

We release [OpenMMLab 2.0](https://openmmlab.com/) with a new core, [MMEngine](https://github.com/open-mmlab/mmengine). (Sept. 2022)

[DenseSiam](https://arxiv.org/abs/2203.11075) is accepted by ECCV 2022. (Jul., 2022)

[Video K-Net](https://arxiv.org/abs/2204.04656) is accepted by CVPR 2022 (<font color="Tomato"><strong>oral</strong></font>). (May., 2022)

[K-Net](https://www.mmlab-ntu.com/project/knet/index.html) is accepted by NeurIPS 2021. Code has been released at [here](https://github.com/ZwwWayne/K-Net). (Oct., 2021)

MMDet3D team obtains <font color="Tomato"><strong>Best PKL Award</strong></font> and best vision-only results in the 3rd nuScenes detection challenge of 5th AI Driving Olympics, NeurIPS 2020.
Paper of our multi-modality method is released in [arxiv](https://arxiv.org/abs/2012.12741). (Dec., 2020)

Second runner up in [LVIS2020 Challenge](https://www.lvisdataset.org/challenge_2020). Paper can be found [in arxiv](https://arxiv.org/abs/2008.10032).

We release [MMDetection3D](https://github.com/open-mmlab/mmdetection3d), OpenMMLab's next-generation platform for general 3D object detection. (July, 2020)

One paper is accepted by ECCV 2020 (<font color="Tomato"><strong>spotlight</strong></font>). (July, 2020)

Win the <font color="Tomato"><strong>1st prize</strong></font> in [COCO 2019 Object Detection Challenge](http://cocodataset.org/workshop/coco-mapillary-iccv-2019.html) (no external data). (Team: MMDet)

Academic Service
------------------------

Conference Reviewer: CVPR2020-2023, ICCV2021-2023, ECCV2020-2022, ICLR2022-2023, NeurIPS2021-2022, ICML2023, ACM MM2020.

Committee member and speaker of OpenMMLab Tutorials in CVPR [2021](https://openmmlab.com/community/cvpr2021-tutorial)/[2022](https://openmmlab.com/community/cvpr2022-tutorial), and [AAAI2023](https://openmmlab.com/community/aaai2023-lab)
